"""
ë°ì´í„° ì „ì²˜ë¦¬ ë° ì •í•©ì„± ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
=======================================

CT ì˜ìƒì˜ ì •í•©ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤:
- Resampling: ë‹¤ë¥¸ spacingì„ í‘œì¤€ spacingìœ¼ë¡œ í†µì¼
- Orientation: ì˜ìƒ ë°©í–¥ì„ í‘œì¤€ ë°©í–¥(RAS)ìœ¼ë¡œ í†µì¼
- Intensity normalization: HU ê°’ ì •ê·œí™”
- Cropping/Padding: í‘œì¤€ í¬ê¸°ë¡œ ë§ì¶”ê¸°
"""

import numpy as np
import nibabel as nib
from typing import Tuple, Optional, Union
from pathlib import Path


class CTPreprocessor:
    """
    CT ì˜ìƒ ì „ì²˜ë¦¬ ë° ì •í•©ì„± ì²˜ë¦¬ í´ë˜ìŠ¤

    ì£¼ìš” ê¸°ëŠ¥:
    1. Spacing ì •ê·œí™” (ë¦¬ìƒ˜í”Œë§)
    2. Orientation ì •ê·œí™” (RAS ë°©í–¥ìœ¼ë¡œ í†µì¼)
    3. Intensity ì •ê·œí™” (HU ê°’ í‘œì¤€í™”)
    4. Spatial ì •ê·œí™” (í¬ê¸° í†µì¼)
    """

    def __init__(
        self,
        target_spacing: Tuple[float, float, float] = (1.0, 1.0, 1.0),
        target_size: Optional[Tuple[int, int, int]] = None,
        intensity_range: Tuple[float, float] = (-200, 300),  # ë³µë¶€ CT HU ë²”ìœ„
        normalize_intensity: bool = True,
    ):
        """
        ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”

        Args:
            target_spacing: ëª©í‘œ voxel spacing (mm) (x, y, z)
            target_size: ëª©í‘œ ì˜ìƒ í¬ê¸° (ì„ íƒì‚¬í•­)
            intensity_range: HU ê°’ ìœˆë„ìš° ë²”ìœ„ (min, max)
            normalize_intensity: ê°•ë„ ì •ê·œí™” ì—¬ë¶€
        """
        self.target_spacing = np.array(target_spacing)
        self.target_size = target_size
        self.intensity_range = intensity_range
        self.normalize_intensity = normalize_intensity

    def process(
        self,
        image: np.ndarray,
        spacing: Tuple[float, float, float],
        origin: Optional[Tuple[float, float, float]] = None,
        direction: Optional[np.ndarray] = None,
    ) -> Tuple[np.ndarray, dict]:
        """
        ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

        Args:
            image: ì…ë ¥ ì˜ìƒ (H, W, D)
            spacing: í˜„ì¬ voxel spacing
            origin: ì˜ìƒ ì›ì  (ì„ íƒì‚¬í•­)
            direction: ì˜ìƒ ë°©í–¥ í–‰ë ¬ (ì„ íƒì‚¬í•­)

        Returns:
            processed_image: ì „ì²˜ë¦¬ëœ ì˜ìƒ
            metadata: ì „ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
        """
        metadata = {
            'original_shape': image.shape,
            'original_spacing': spacing,
            'target_spacing': self.target_spacing.tolist(),
        }

        # 1. Spacing ì •ê·œí™” (ë¦¬ìƒ˜í”Œë§)
        if not np.allclose(spacing, self.target_spacing):
            print(f"   ë¦¬ìƒ˜í”Œë§: {spacing} â†’ {self.target_spacing}")
            image = self._resample(image, spacing, self.target_spacing)
            metadata['resampled'] = True
        else:
            metadata['resampled'] = False

        # 2. Intensity ì •ê·œí™”
        if self.normalize_intensity:
            image = self._normalize_intensity(image)
            metadata['intensity_normalized'] = True
        else:
            metadata['intensity_normalized'] = False

        # 3. í¬ê¸° ì •ê·œí™” (í•„ìš”ì‹œ)
        if self.target_size is not None:
            image = self._resize_or_pad(image, self.target_size)
            metadata['resized'] = True
            metadata['final_shape'] = image.shape
        else:
            metadata['resized'] = False
            metadata['final_shape'] = image.shape

        return image, metadata

    def _resample(
        self,
        image: np.ndarray,
        original_spacing: Tuple[float, float, float],
        target_spacing: Tuple[float, float, float],
    ) -> np.ndarray:
        """
        ì˜ìƒ ë¦¬ìƒ˜í”Œë§

        Args:
            image: ì…ë ¥ ì˜ìƒ
            original_spacing: ì›ë³¸ spacing
            target_spacing: ëª©í‘œ spacing

        Returns:
            ë¦¬ìƒ˜í”Œë§ëœ ì˜ìƒ
        """
        from scipy.ndimage import zoom

        # ë¦¬ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°
        zoom_factors = np.array(original_spacing) / np.array(target_spacing)

        # scipy.ndimage.zoom ì‚¬ìš©
        resampled = zoom(image, zoom_factors, order=3)  # order=3: cubic interpolation

        return resampled

    def _normalize_intensity(self, image: np.ndarray) -> np.ndarray:
        """
        HU ê°’ ì •ê·œí™”

        1. ìœˆë„ì‰: intensity_rangeë¡œ í´ë¦¬í•‘
        2. 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”

        Args:
            image: ì…ë ¥ ì˜ìƒ

        Returns:
            ì •ê·œí™”ëœ ì˜ìƒ
        """
        # HU ìœˆë„ì‰
        image = np.clip(image, self.intensity_range[0], self.intensity_range[1])

        # 0-1 ì •ê·œí™”
        image = (image - self.intensity_range[0]) / (
            self.intensity_range[1] - self.intensity_range[0]
        )

        return image.astype(np.float32)

    def _resize_or_pad(
        self,
        image: np.ndarray,
        target_size: Tuple[int, int, int],
    ) -> np.ndarray:
        """
        ì˜ìƒì„ ëª©í‘œ í¬ê¸°ë¡œ ë§ì¶”ê¸° (crop ë˜ëŠ” pad)

        Args:
            image: ì…ë ¥ ì˜ìƒ
            target_size: ëª©í‘œ í¬ê¸°

        Returns:
            í¬ê¸°ê°€ ì¡°ì •ëœ ì˜ìƒ
        """
        current_size = np.array(image.shape)
        target_size = np.array(target_size)

        # Crop ë˜ëŠ” Pad ê³„ì‚°
        result = np.zeros(target_size, dtype=image.dtype)

        # ë³µì‚¬í•  ì˜ì—­ ê³„ì‚°
        copy_from = np.maximum(0, (current_size - target_size) // 2)
        copy_to = copy_from + np.minimum(current_size, target_size)

        paste_from = np.maximum(0, (target_size - current_size) // 2)
        paste_to = paste_from + np.minimum(current_size, target_size)

        # ë°ì´í„° ë³µì‚¬
        result[
            paste_from[0]:paste_to[0],
            paste_from[1]:paste_to[1],
            paste_from[2]:paste_to[2]
        ] = image[
            copy_from[0]:copy_to[0],
            copy_from[1]:copy_to[1],
            copy_from[2]:copy_to[2]
        ]

        return result


class ConsistencyValidator:
    """
    ë°ì´í„°ì…‹ ì „ì²´ì˜ ì •í•©ì„± ê²€ì¦

    ì—¬ëŸ¬ CT ìŠ¤ìº”ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê²€ì¦í•˜ê³  í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self):
        self.spacings = []
        self.shapes = []
        self.intensity_ranges = []

    def add_sample(
        self,
        image: np.ndarray,
        spacing: Tuple[float, float, float],
    ):
        """ìƒ˜í”Œ ì¶”ê°€ ë° ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘"""
        self.spacings.append(spacing)
        self.shapes.append(image.shape)
        self.intensity_ranges.append((image.min(), image.max()))

    def validate(self, tolerance: float = 0.1) -> dict:
        """
        ì •í•©ì„± ê²€ì¦

        Args:
            tolerance: spacing ì°¨ì´ í—ˆìš© ì˜¤ì°¨ (mm)

        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.spacings:
            return {'valid': False, 'reason': 'ìƒ˜í”Œ ì—†ìŒ'}

        spacings = np.array(self.spacings)
        shapes = np.array(self.shapes)

        # Spacing ì¼ê´€ì„± ê²€ì‚¬
        mean_spacing = spacings.mean(axis=0)
        spacing_std = spacings.std(axis=0)
        spacing_consistent = np.all(spacing_std < tolerance)

        # Shape ì¼ê´€ì„± ê²€ì‚¬
        unique_shapes = np.unique(shapes, axis=0)
        shape_consistent = len(unique_shapes) == 1

        # Intensity ë²”ìœ„ ê²€ì‚¬
        intensity_ranges = np.array(self.intensity_ranges)

        return {
            'valid': spacing_consistent and shape_consistent,
            'num_samples': len(self.spacings),
            'spacing': {
                'consistent': spacing_consistent,
                'mean': mean_spacing.tolist(),
                'std': spacing_std.tolist(),
                'min': spacings.min(axis=0).tolist(),
                'max': spacings.max(axis=0).tolist(),
            },
            'shape': {
                'consistent': shape_consistent,
                'unique_shapes': unique_shapes.tolist(),
                'most_common': shapes[0].tolist(),
            },
            'intensity': {
                'min': intensity_ranges[:, 0].min(),
                'max': intensity_ranges[:, 1].max(),
                'mean_min': intensity_ranges[:, 0].mean(),
                'mean_max': intensity_ranges[:, 1].mean(),
            }
        }

    def get_recommended_settings(self) -> dict:
        """
        ì „ì²˜ë¦¬ ê¶Œì¥ ì„¤ì • ë°˜í™˜

        Returns:
            ê¶Œì¥ ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
        """
        if not self.spacings:
            return {}

        spacings = np.array(self.spacings)
        shapes = np.array(self.shapes)
        intensity_ranges = np.array(self.intensity_ranges)

        # ì¤‘ì•™ê°’ spacing ì‚¬ìš© (í‰ê· ë³´ë‹¤ ì´ìƒì¹˜ì— robust)
        median_spacing = np.median(spacings, axis=0)

        # ê°€ì¥ í° í¬ê¸° ì‚¬ìš© (ì •ë³´ ì†ì‹¤ ìµœì†Œí™”)
        max_shape = shapes.max(axis=0)

        # Intensity ë²”ìœ„ (1-99 percentile)
        all_intensities = np.concatenate([
            np.array([r[0], r[1]]) for r in self.intensity_ranges
        ])
        intensity_min = np.percentile(all_intensities, 1)
        intensity_max = np.percentile(all_intensities, 99)

        return {
            'target_spacing': median_spacing.tolist(),
            'target_size': max_shape.tolist(),
            'intensity_range': (float(intensity_min), float(intensity_max)),
        }


def validate_and_preprocess_dataset(
    data_dir: Path,
    output_dir: Path,
    target_spacing: Optional[Tuple[float, float, float]] = None,
) -> dict:
    """
    ë°ì´í„°ì…‹ ì „ì²´ ê²€ì¦ ë° ì „ì²˜ë¦¬

    Args:
        data_dir: ì…ë ¥ ë°ì´í„° ë””ë ‰í† ë¦¬
        output_dir: ì „ì²˜ë¦¬ëœ ë°ì´í„° ì¶œë ¥ ë””ë ‰í† ë¦¬
        target_spacing: ëª©í‘œ spacing (Noneì´ë©´ ìë™ ê²°ì •)

    Returns:
        ì „ì²˜ë¦¬ ê²°ê³¼ ë° í†µê³„
    """
    validator = ConsistencyValidator()

    # 1. ëª¨ë“  NIfTI íŒŒì¼ ìˆ˜ì§‘
    nifti_files = list(data_dir.glob("*.nii.gz"))

    print(f"ğŸ” {len(nifti_files)}ê°œ íŒŒì¼ ë¶„ì„ ì¤‘...")

    # 2. ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
    for nii_file in nifti_files:
        nii = nib.load(str(nii_file))
        data = nii.get_fdata()
        spacing = nii.header.get_zooms()

        validator.add_sample(data, spacing)

    # 3. ê²€ì¦
    validation_result = validator.validate()
    print("\nğŸ“Š ë°ì´í„°ì…‹ ì¼ê´€ì„± ê²€ì¦:")
    print(f"   ìƒ˜í”Œ ìˆ˜: {validation_result['num_samples']}")
    print(f"   Spacing ì¼ê´€ì„±: {'âœ…' if validation_result['spacing']['consistent'] else 'âŒ'}")
    print(f"   Shape ì¼ê´€ì„±: {'âœ…' if validation_result['shape']['consistent'] else 'âŒ'}")

    # 4. ê¶Œì¥ ì„¤ì •
    recommended = validator.get_recommended_settings()
    print("\nğŸ’¡ ê¶Œì¥ ì „ì²˜ë¦¬ ì„¤ì •:")
    print(f"   Target spacing: {recommended['target_spacing']}")
    print(f"   Target size: {recommended['target_size']}")
    print(f"   Intensity range: {recommended['intensity_range']}")

    # 5. ì „ì²˜ë¦¬ ìˆ˜í–‰ (í•„ìš”ì‹œ)
    if target_spacing is None:
        target_spacing = tuple(recommended['target_spacing'])

    preprocessor = CTPreprocessor(
        target_spacing=target_spacing,
        intensity_range=recommended['intensity_range'],
    )

    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ”„ ì „ì²˜ë¦¬ ì‹œì‘...")
    for nii_file in nifti_files:
        nii = nib.load(str(nii_file))
        data = nii.get_fdata()
        spacing = nii.header.get_zooms()

        # ì „ì²˜ë¦¬
        processed, metadata = preprocessor.process(data, spacing)

        # ì €ì¥
        output_file = output_dir / nii_file.name
        processed_nii = nib.Nifti1Image(processed, affine=np.eye(4))
        processed_nii.header.set_zooms(target_spacing)
        nib.save(processed_nii, str(output_file))

        print(f"   âœ“ {nii_file.name}")

    return {
        'validation': validation_result,
        'recommended_settings': recommended,
        'preprocessed_files': len(nifti_files),
    }
