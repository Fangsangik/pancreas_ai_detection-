
import os
import argparse
import torch
import torch.nn as nn
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, Callback
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix

# --- í”„ë¡œì íŠ¸ì˜ ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸ ---
# ê²½ë¡œ ì„¤ì •ì„ ìœ„í•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
import sys
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.insert(0, project_root)

from pancreas_cancer_diagnosis.data.datamodule import SegmentationDataModule
from pancreas_cancer_diagnosis.segmentation.models.unet import UNet3D

# --- ê°€ì¤‘ì¹˜ ì†ì‹¤ í•¨ìˆ˜ ì •ì˜ ---
class WeightedMSELoss(nn.Module):
    """ì·Œì¥ ì˜ì—­ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” MSE ì†ì‹¤ í•¨ìˆ˜"""
    def __init__(self, pancreas_weight: float = 10.0):
        super().__init__()
        self.pancreas_weight = pancreas_weight
        self.mse_loss = nn.MSELoss(reduction='none')

    def forward(self, recon, original, pancreas_mask):
        # í”½ì…€ë³„ MSE ê³„ì‚°
        loss = self.mse_loss(recon, original)

        # ê°€ì¤‘ì¹˜ ë§µ ìƒì„± (ì·Œì¥ ì˜ì—­ì€ ë†’ì€ ê°€ì¤‘ì¹˜, ë°°ê²½ì€ 1)
        weight_map = torch.ones_like(pancreas_mask)
        weight_map[pancreas_mask > 0] = self.pancreas_weight

        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_loss = loss * weight_map

        # ì „ì²´ ì†ì‹¤ì˜ í‰ê·  ê³„ì‚°
        return weighted_loss.mean()

# --- ë©”íŠ¸ë¦­ ì‹œê°í™” í•¨ìˆ˜ ---
def plot_metrics(metrics, output_dir):
    """í•™ìŠµ ë©”íŠ¸ë¦­ì„ ê·¸ë˜í”„ë¡œ ì‹œê°í™”"""
    epochs = range(1, len(metrics['train_loss']) + 1)

    # 2x3 subplot ìƒì„±
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Autoencoder Training Metrics', fontsize=16, fontweight='bold')

    # 1. Train/Val Loss
    ax = axes[0, 0]
    if len(metrics['train_loss']) > 0:
        ax.plot(epochs, metrics['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=8)
    if len(metrics['val_loss']) > 0:
        ax.plot(epochs, metrics['val_loss'], 'r-o', label='Val Loss', linewidth=2, markersize=8)
    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('Loss', fontsize=12)
    ax.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)

    # 2. AUC
    ax = axes[0, 1]
    if len(metrics['auc']) > 0:
        ax.plot(epochs[:len(metrics['auc'])], metrics['auc'], 'g-o', linewidth=2, markersize=8)
        ax.set_xlabel('Epoch', fontsize=12)
        ax.set_ylabel('AUC', fontsize=12)
        ax.set_title('AUC Score', fontsize=14, fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, 'No AUC data', ha='center', va='center', fontsize=12)
        ax.set_title('AUC Score', fontsize=14, fontweight='bold')

    # 3. Sensitivity (Recall)
    ax = axes[0, 2]
    if len(metrics['sensitivity']) > 0:
        ax.plot(epochs[:len(metrics['sensitivity'])], metrics['sensitivity'], 'm-o', linewidth=2, markersize=8)
        ax.set_xlabel('Epoch', fontsize=12)
        ax.set_ylabel('Sensitivity', fontsize=12)
        ax.set_title('Sensitivity (Recall)', fontsize=14, fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, 'No Sensitivity data', ha='center', va='center', fontsize=12)
        ax.set_title('Sensitivity (Recall)', fontsize=14, fontweight='bold')

    # 4. Specificity
    ax = axes[1, 0]
    if len(metrics['specificity']) > 0:
        ax.plot(epochs[:len(metrics['specificity'])], metrics['specificity'], 'c-o', linewidth=2, markersize=8)
        ax.set_xlabel('Epoch', fontsize=12)
        ax.set_ylabel('Specificity', fontsize=12)
        ax.set_title('Specificity', fontsize=14, fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, 'No Specificity data', ha='center', va='center', fontsize=12)
        ax.set_title('Specificity', fontsize=14, fontweight='bold')

    # 5. Accuracy
    ax = axes[1, 1]
    if len(metrics['accuracy']) > 0:
        ax.plot(epochs[:len(metrics['accuracy'])], metrics['accuracy'], 'orange', marker='o', linewidth=2, markersize=8)
        ax.set_xlabel('Epoch', fontsize=12)
        ax.set_ylabel('Accuracy', fontsize=12)
        ax.set_title('Accuracy', fontsize=14, fontweight='bold')
        ax.set_ylim([0, 1])
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, 'No Accuracy data', ha='center', va='center', fontsize=12)
        ax.set_title('Accuracy', fontsize=14, fontweight='bold')

    # 6. All metrics together
    ax = axes[1, 2]
    if len(metrics['auc']) > 0:
        ax.plot(epochs[:len(metrics['auc'])], metrics['auc'], 'g-o', label='AUC', linewidth=2, markersize=6)
    if len(metrics['sensitivity']) > 0:
        ax.plot(epochs[:len(metrics['sensitivity'])], metrics['sensitivity'], 'm-o', label='Sensitivity', linewidth=2, markersize=6)
    if len(metrics['specificity']) > 0:
        ax.plot(epochs[:len(metrics['specificity'])], metrics['specificity'], 'c-o', label='Specificity', linewidth=2, markersize=6)
    if len(metrics['accuracy']) > 0:
        ax.plot(epochs[:len(metrics['accuracy'])], metrics['accuracy'], 'orange', marker='o', label='Accuracy', linewidth=2, markersize=6)
    ax.set_xlabel('Epoch', fontsize=12)
    ax.set_ylabel('Score', fontsize=12)
    ax.set_title('All Metrics', fontsize=14, fontweight='bold')
    ax.set_ylim([0, 1])
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)

    plt.tight_layout()

    # ì €ì¥
    save_path = os.path.join(output_dir, 'training_metrics.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close(fig)
    print(f"âœ… ë©”íŠ¸ë¦­ ê·¸ë˜í”„ ì €ì¥: {save_path}")

    # ìµœì¢… ë©”íŠ¸ë¦­ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š ìµœì¢… ë©”íŠ¸ë¦­ ìš”ì•½")
    print("="*60)
    if len(metrics['auc']) > 0:
        print(f"ìµœì¢… AUC:         {metrics['auc'][-1]:.4f}")
    if len(metrics['sensitivity']) > 0:
        print(f"ìµœì¢… Sensitivity: {metrics['sensitivity'][-1]:.4f}")
    if len(metrics['specificity']) > 0:
        print(f"ìµœì¢… Specificity: {metrics['specificity'][-1]:.4f}")
    if len(metrics['accuracy']) > 0:
        print(f"ìµœì¢… Accuracy:    {metrics['accuracy'][-1]:.4f}")
    print("="*60 + "\n")

# --- ì‹œê°í™” ì½œë°± ì •ì˜ ---
class VisualizationCallback(Callback):
    """ê²€ì¦ ë‹¨ê³„ì—ì„œ ì›ë³¸/ë³µì›/ì˜¤ë¥˜ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ëŠ” ì½œë°±"""
    def __init__(self, output_dir: str, freq: int = 5):
        super().__init__()
        self.output_dir = output_dir
        self.freq = freq
        os.makedirs(self.output_dir, exist_ok=True)

    def on_validation_epoch_end(self, trainer, pl_module):
        """ê²€ì¦ ì—í­ì´ ëë‚  ë•Œë§ˆë‹¤ í˜¸ì¶œ"""
        if (trainer.current_epoch + 1) % self.freq != 0:
            return

        # ê²€ì¦ ë°ì´í„°ë¡œë”ì—ì„œ í•œ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
        val_dataloader = trainer.datamodule.val_dataloader()
        if not val_dataloader:
            return
        
        try:
            batch = next(iter(val_dataloader))
        except StopIteration:
            return # ë°ì´í„°ë¡œë”ê°€ ë¹„ì–´ìˆì„ ê²½ìš°

        images, labels = batch['image'].to(pl_module.device), batch['label'].to(pl_module.device)

        # Ensure 5D tensors: [B, C, D, H, W]
        if images.ndim == 4:  # [B, D, H, W]
            images = images.unsqueeze(1)  # [B, 1, D, H, W]
        if labels.ndim == 4:  # [B, D, H, W]
            labels = labels.unsqueeze(1)  # [B, 1, D, H, W]

        # í•œ ê°œì˜ ìƒ˜í”Œ ì„ íƒ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
        image = images[0].unsqueeze(0)
        label = labels[0].unsqueeze(0)

        # ëª¨ë¸ ì¶”ë¡ 
        pl_module.eval()
        with torch.no_grad():
            recon = pl_module(image)
        pl_module.train()

        # CPUë¡œ ë°ì´í„° ì´ë™ ë° numpy ë³€í™˜
        image_np = image.cpu().numpy().squeeze()
        recon_np = recon.cpu().numpy().squeeze()
        label_np = label.cpu().numpy().squeeze()

        # ì¤‘ì•™ ìŠ¬ë¼ì´ìŠ¤ ì„ íƒ
        mid_slice_idx = image_np.shape[0] // 2
        img_slice = image_np[mid_slice_idx, :, :]
        recon_slice = recon_np[mid_slice_idx, :, :]
        label_slice = label_np[mid_slice_idx, :, :]
        error_map = np.abs(img_slice - recon_slice)

        # ì‹œê°í™”
        fig, axes = plt.subplots(1, 4, figsize=(20, 5))
        fig.suptitle(f'Epoch {trainer.current_epoch + 1}', fontsize=16)

        axes[0].imshow(img_slice, cmap='gray')
        axes[0].set_title('Original Image')
        axes[0].axis('off')

        axes[1].imshow(recon_slice, cmap='gray')
        axes[1].set_title('Reconstructed Image')
        axes[1].axis('off')

        im = axes[2].imshow(error_map, cmap='hot')
        axes[2].set_title('Reconstruction Error')
        axes[2].axis('off')
        fig.colorbar(im, ax=axes[2])

        axes[3].imshow(label_slice, cmap='gray')
        axes[3].set_title('Pancreas Label')
        axes[3].axis('off')

        # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
        save_path = os.path.join(self.output_dir, f'epoch_{trainer.current_epoch + 1}.png')
        plt.savefig(save_path)
        plt.close(fig)
        print(f"\nâœ… Visualization saved to {save_path}")

# --- PyTorch Lightning ëª¨ë¸ ì •ì˜ ---
class LitAutoencoder(pl.LightningModule):
    def __init__(self, learning_rate=1e-4, pancreas_weight=10.0):
        super().__init__()
        self.save_hyperparameters()

        # ê¸°ì¡´ U-Net ëª¨ë¸ì„ ì˜¤í† ì¸ì½”ë”ë¡œ ì‚¬ìš©
        self.model = UNet3D(in_channels=1, num_classes=1) # ì¶œë ¥ ì±„ë„ì„ 1ë¡œ ë³€ê²½
        self.loss_fn = WeightedMSELoss(pancreas_weight=pancreas_weight)

        # ë©”íŠ¸ë¦­ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
        self.validation_step_outputs = []
        self.epoch_metrics = {
            'train_loss': [],
            'val_loss': [],
            'auc': [],
            'sensitivity': [],
            'specificity': [],
            'accuracy': []
        }

    def forward(self, x):
        # U-Netì˜ ì¶œë ¥ì´ ë³µì›ëœ ì´ë¯¸ì§€ê°€ ë˜ë„ë¡ í•¨
        return self.model(x)

    def training_step(self, batch, batch_idx):
        images, labels = batch['image'], batch['label']

        # Ensure 5D tensors: [B, C, D, H, W]
        if images.ndim == 4:  # [B, D, H, W]
            images = images.unsqueeze(1)  # [B, 1, D, H, W]
        if labels.ndim == 4:  # [B, D, H, W]
            labels = labels.unsqueeze(1)  # [B, 1, D, H, W]

        recons = self(images)
        loss = self.loss_fn(recons, images, labels)
        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)
        return loss

    def validation_step(self, batch, batch_idx):
        images, labels = batch['image'], batch['label']

        # Ensure 5D tensors: [B, C, D, H, W]
        if images.ndim == 4:  # [B, D, H, W]
            images = images.unsqueeze(1)  # [B, 1, D, H, W]
        if labels.ndim == 4:  # [B, D, H, W]
            labels = labels.unsqueeze(1)  # [B, 1, D, H, W]

        recons = self(images)
        loss = self.loss_fn(recons, images, labels)

        # Reconstruction error ê³„ì‚° (anomaly scoreë¡œ ì‚¬ìš©)
        recon_error = torch.mean((recons - images) ** 2, dim=[1, 2, 3, 4])  # [B]

        # ì·Œì¥ ì˜ì—­ì´ ìˆìœ¼ë©´ anomaly (class 1), ì—†ìœ¼ë©´ normal (class 0)
        # ì‹¤ì œë¡œëŠ” tumor ì˜ì—­ ê¸°ì¤€ì´ì–´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì·Œì¥ ì¡´ì¬ ì—¬ë¶€ë¡œ ê°„ë‹¨íˆ ì²˜ë¦¬
        has_pancreas = (torch.sum(labels, dim=[1, 2, 3, 4]) > 0).float()

        self.validation_step_outputs.append({
            'recon_error': recon_error.cpu(),
            'labels': has_pancreas.cpu(),
            'loss': loss
        })

        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)
        return loss

    def on_validation_epoch_end(self):
        """ê²€ì¦ ì—í­ ì¢…ë£Œ ì‹œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if len(self.validation_step_outputs) == 0:
            return

        # ëª¨ë“  validation outputs ìˆ˜ì§‘
        all_errors = torch.cat([x['recon_error'] for x in self.validation_step_outputs])
        all_labels = torch.cat([x['labels'] for x in self.validation_step_outputs])
        avg_loss = torch.stack([x['loss'] for x in self.validation_step_outputs]).mean()

        # ë©”íŠ¸ë¦­ ê³„ì‚° (ìµœì†Œ 2ê°œ ì´ìƒì˜ ìƒ˜í”Œì´ í•„ìš”)
        if len(all_errors) >= 2 and len(torch.unique(all_labels)) >= 2:
            try:
                # AUC ê³„ì‚°
                auc = roc_auc_score(all_labels.numpy(), all_errors.numpy())

                # Thresholdë¥¼ medianìœ¼ë¡œ ì„¤ì •í•˜ì—¬ binary prediction ìƒì„±
                threshold = torch.median(all_errors).item()
                predictions = (all_errors > threshold).float()

                # Confusion matrix ê³„ì‚°
                tn, fp, fn, tp = confusion_matrix(all_labels.numpy(), predictions.numpy()).ravel()

                # ë©”íŠ¸ë¦­ ê³„ì‚°
                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
                accuracy = (tp + tn) / (tp + tn + fp + fn)

                # ë©”íŠ¸ë¦­ ì €ì¥
                self.epoch_metrics['auc'].append(auc)
                self.epoch_metrics['sensitivity'].append(sensitivity)
                self.epoch_metrics['specificity'].append(specificity)
                self.epoch_metrics['accuracy'].append(accuracy)

                # ë¡œê¹…
                self.log('auc', auc, prog_bar=True)
                self.log('sensitivity', sensitivity, prog_bar=True)
                self.log('specificity', specificity, prog_bar=True)
                self.log('accuracy', accuracy, prog_bar=True)

                print(f"\nğŸ“Š Epoch {self.current_epoch} Metrics:")
                print(f"   AUC: {auc:.4f}")
                print(f"   Sensitivity: {sensitivity:.4f}")
                print(f"   Specificity: {specificity:.4f}")
                print(f"   Accuracy: {accuracy:.4f}")

            except Exception as e:
                print(f"âš ï¸  ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")

        # ì—í­ ì†ì‹¤ ì €ì¥
        train_loss_val = self.trainer.callback_metrics.get('train_loss_epoch', 0)
        train_loss_val = train_loss_val.item() if hasattr(train_loss_val, 'item') else train_loss_val
        self.epoch_metrics['train_loss'].append(train_loss_val)
        self.epoch_metrics['val_loss'].append(avg_loss.item())

        # outputs ì´ˆê¸°í™”
        self.validation_step_outputs.clear()

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---
def main(args):
    # ë°ì´í„° ëª¨ë“ˆ ì¤€ë¹„ (dataset ë‚´ë¶€ì—ì„œ 64x64x64ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)
    dm = SegmentationDataModule(
        data_root=args.data_root,
        data_list_file=args.data_list_file,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        num_classes=1, # ë ˆì´ë¸”ì˜ í´ë˜ìŠ¤ ìˆ˜ (ì—¬ê¸°ì„œëŠ” ì·Œì¥ í•˜ë‚˜ë§Œ í•„ìš”)
        train_transform=None,  # datasetì—ì„œ ìë™ ë¦¬ì‚¬ì´ì¦ˆ
        val_transform=None
    )

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = LitAutoencoder(
        learning_rate=args.learning_rate,
        pancreas_weight=args.pancreas_weight
    )

    # ì½œë°± ì¤€ë¹„
    checkpoint_callback = ModelCheckpoint(
        dirpath=os.path.join(args.output_dir, 'checkpoints'),
        filename='best-model-{epoch:02d}-{val_loss:.2f}',
        save_top_k=1,
        monitor='val_loss',
        mode='min'
    )
    vis_callback = VisualizationCallback(
        output_dir=os.path.join(args.output_dir, 'visualizations')
    )

    # íŠ¸ë ˆì´ë„ˆ ì¤€ë¹„
    # ê°€ì†ê¸° ìë™ ì„ íƒ (CUDAë§Œ ì‚¬ìš©, MPSëŠ” max_pool3d ë¯¸ì§€ì›)
    if torch.cuda.is_available():
        accelerator = 'gpu'
    else:
        # MPSëŠ” 3D ì—°ì‚° ë¯¸ì§€ì›, CPU ì‚¬ìš©
        accelerator = 'cpu'

    trainer = pl.Trainer(
        max_epochs=args.epochs,
        accelerator=accelerator,
        devices=1,
        callbacks=[checkpoint_callback, vis_callback],
        default_root_dir=args.output_dir
    )

    # í•™ìŠµ ì‹œì‘
    print("--- ì´ìƒ íƒì§€ ì˜¤í† ì¸ì½”ë” í•™ìŠµ ì‹œì‘ ---")
    trainer.fit(model, dm)
    print("--- í•™ìŠµ ì™„ë£Œ ---")

    # ë©”íŠ¸ë¦­ ê·¸ë˜í”„ ìƒì„±
    print("\nğŸ“ˆ ë©”íŠ¸ë¦­ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
    plot_metrics(model.epoch_metrics, args.output_dir)

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Anomaly Detection Autoencoder Training')

    # ë°ì´í„° ê´€ë ¨ ì¸ì
    parser.add_argument('--data_root', type=str, default='data', help='NIfTI íŒŒì¼ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--data_list_file', type=str, default='data/manifests/pancreas_ct_manifest.json', help='ì „ì²´ ë°ì´í„° ëª©ë¡ JSON')
    parser.add_argument('--batch_size', type=int, default=1, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--num_workers', type=int, default=4, help='ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜')

    # í•™ìŠµ ê´€ë ¨ ì¸ì
    parser.add_argument('--epochs', type=int, default=50, help='ì´ í•™ìŠµ ì—í­')
    parser.add_argument('--learning_rate', type=float, default=1e-4, help='í•™ìŠµë¥ ')
    parser.add_argument('--pancreas_weight', type=float, default=10.0, help='ì·Œì¥ ì˜ì—­ ì†ì‹¤ ê°€ì¤‘ì¹˜')

    # ì¶œë ¥ ê´€ë ¨ ì¸ì
    parser.add_argument('--output_dir', type=str, default='outputs/anomaly_detection', help='í•™ìŠµ ê²°ê³¼ë¬¼ ì €ì¥ ë””ë ‰í† ë¦¬')

    args = parser.parse_args()

    main(args)
